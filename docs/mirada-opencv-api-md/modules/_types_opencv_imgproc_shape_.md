[mirada](../README.md) › ["types/opencv/imgproc_shape"](_types_opencv_imgproc_shape_.md)

# External module: "types/opencv/imgproc_shape"


## Index

### Type aliases

* [ConnectedComponentsAlgorithmsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentsalgorithmstypes)
* [ConnectedComponentsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentstypes)
* [ContourApproximationModes](_types_opencv_imgproc_shape_.md#contourapproximationmodes)
* [RectanglesIntersectTypes](_types_opencv_imgproc_shape_.md#rectanglesintersecttypes)
* [RetrievalModes](_types_opencv_imgproc_shape_.md#retrievalmodes)
* [ShapeMatchModes](_types_opencv_imgproc_shape_.md#shapematchmodes)

### Variables

* [CCL_DEFAULT](_types_opencv_imgproc_shape_.md#const-ccl_default)
* [CCL_GRANA](_types_opencv_imgproc_shape_.md#const-ccl_grana)
* [CCL_WU](_types_opencv_imgproc_shape_.md#const-ccl_wu)
* [CC_STAT_AREA](_types_opencv_imgproc_shape_.md#const-cc_stat_area)
* [CC_STAT_HEIGHT](_types_opencv_imgproc_shape_.md#const-cc_stat_height)
* [CC_STAT_LEFT](_types_opencv_imgproc_shape_.md#const-cc_stat_left)
* [CC_STAT_MAX](_types_opencv_imgproc_shape_.md#const-cc_stat_max)
* [CC_STAT_TOP](_types_opencv_imgproc_shape_.md#const-cc_stat_top)
* [CC_STAT_WIDTH](_types_opencv_imgproc_shape_.md#const-cc_stat_width)
* [CHAIN_APPROX_NONE](_types_opencv_imgproc_shape_.md#const-chain_approx_none)
* [CHAIN_APPROX_SIMPLE](_types_opencv_imgproc_shape_.md#const-chain_approx_simple)
* [CHAIN_APPROX_TC89_KCOS](_types_opencv_imgproc_shape_.md#const-chain_approx_tc89_kcos)
* [CHAIN_APPROX_TC89_L1](_types_opencv_imgproc_shape_.md#const-chain_approx_tc89_l1)
* [CONTOURS_MATCH_I1](_types_opencv_imgproc_shape_.md#const-contours_match_i1)
* [CONTOURS_MATCH_I2](_types_opencv_imgproc_shape_.md#const-contours_match_i2)
* [CONTOURS_MATCH_I3](_types_opencv_imgproc_shape_.md#const-contours_match_i3)
* [INTERSECT_FULL](_types_opencv_imgproc_shape_.md#const-intersect_full)
* [INTERSECT_NONE](_types_opencv_imgproc_shape_.md#const-intersect_none)
* [INTERSECT_PARTIAL](_types_opencv_imgproc_shape_.md#const-intersect_partial)
* [RETR_CCOMP](_types_opencv_imgproc_shape_.md#const-retr_ccomp)
* [RETR_EXTERNAL](_types_opencv_imgproc_shape_.md#const-retr_external)
* [RETR_FLOODFILL](_types_opencv_imgproc_shape_.md#const-retr_floodfill)
* [RETR_LIST](_types_opencv_imgproc_shape_.md#const-retr_list)
* [RETR_TREE](_types_opencv_imgproc_shape_.md#const-retr_tree)

### Functions

* [HuMoments](_types_opencv_imgproc_shape_.md#humoments)
* [approxPolyDP](_types_opencv_imgproc_shape_.md#approxpolydp)
* [arcLength](_types_opencv_imgproc_shape_.md#arclength)
* [boundingRect](_types_opencv_imgproc_shape_.md#boundingrect)
* [boxPoints](_types_opencv_imgproc_shape_.md#boxpoints)
* [connectedComponents](_types_opencv_imgproc_shape_.md#connectedcomponents)
* [connectedComponentsWithStats](_types_opencv_imgproc_shape_.md#connectedcomponentswithstats)
* [contourArea](_types_opencv_imgproc_shape_.md#contourarea)
* [convexHull](_types_opencv_imgproc_shape_.md#convexhull)
* [convexityDefects](_types_opencv_imgproc_shape_.md#convexitydefects)
* [createGeneralizedHoughBallard](_types_opencv_imgproc_shape_.md#creategeneralizedhoughballard)
* [createGeneralizedHoughGuil](_types_opencv_imgproc_shape_.md#creategeneralizedhoughguil)
* [findContours](_types_opencv_imgproc_shape_.md#findcontours)
* [fitEllipse](_types_opencv_imgproc_shape_.md#fitellipse)
* [fitEllipseAMS](_types_opencv_imgproc_shape_.md#fitellipseams)
* [fitEllipseDirect](_types_opencv_imgproc_shape_.md#fitellipsedirect)
* [fitLine](_types_opencv_imgproc_shape_.md#fitline)
* [intersectConvexConvex](_types_opencv_imgproc_shape_.md#intersectconvexconvex)
* [isContourConvex](_types_opencv_imgproc_shape_.md#iscontourconvex)
* [matchShapes](_types_opencv_imgproc_shape_.md#matchshapes)
* [minAreaRect](_types_opencv_imgproc_shape_.md#minarearect)
* [minEnclosingCircle](_types_opencv_imgproc_shape_.md#minenclosingcircle)
* [minEnclosingTriangle](_types_opencv_imgproc_shape_.md#minenclosingtriangle)
* [moments](_types_opencv_imgproc_shape_.md#moments)
* [pointPolygonTest](_types_opencv_imgproc_shape_.md#pointpolygontest)
* [rotatedRectangleIntersection](_types_opencv_imgproc_shape_.md#rotatedrectangleintersection)

## Type aliases

###  ConnectedComponentsAlgorithmsTypes

Ƭ **ConnectedComponentsAlgorithmsTypes**: *any*

*Defined in [types/opencv/imgproc_shape.ts:624](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L624)*

___

###  ConnectedComponentsTypes

Ƭ **ConnectedComponentsTypes**: *any*

*Defined in [types/opencv/imgproc_shape.ts:626](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L626)*

___

###  ContourApproximationModes

Ƭ **ContourApproximationModes**: *any*

*Defined in [types/opencv/imgproc_shape.ts:628](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L628)*

___

###  RectanglesIntersectTypes

Ƭ **RectanglesIntersectTypes**: *any*

*Defined in [types/opencv/imgproc_shape.ts:630](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L630)*

___

###  RetrievalModes

Ƭ **RetrievalModes**: *any*

*Defined in [types/opencv/imgproc_shape.ts:632](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L632)*

___

###  ShapeMatchModes

Ƭ **ShapeMatchModes**: *any*

*Defined in [types/opencv/imgproc_shape.ts:634](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L634)*

## Variables

### `Const` CCL_DEFAULT

• **CCL_DEFAULT**: *[ConnectedComponentsAlgorithmsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentsalgorithmstypes)*

*Defined in [types/opencv/imgproc_shape.ts:529](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L529)*

___

### `Const` CCL_GRANA

• **CCL_GRANA**: *[ConnectedComponentsAlgorithmsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentsalgorithmstypes)*

*Defined in [types/opencv/imgproc_shape.ts:531](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L531)*

___

### `Const` CCL_WU

• **CCL_WU**: *[ConnectedComponentsAlgorithmsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentsalgorithmstypes)*

*Defined in [types/opencv/imgproc_shape.ts:527](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L527)*

___

### `Const` CC_STAT_AREA

• **CC_STAT_AREA**: *[ConnectedComponentsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentstypes)*

*Defined in [types/opencv/imgproc_shape.ts:551](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L551)*

___

### `Const` CC_STAT_HEIGHT

• **CC_STAT_HEIGHT**: *[ConnectedComponentsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentstypes)*

*Defined in [types/opencv/imgproc_shape.ts:549](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L549)*

___

### `Const` CC_STAT_LEFT

• **CC_STAT_LEFT**: *[ConnectedComponentsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentstypes)*

*Defined in [types/opencv/imgproc_shape.ts:538](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L538)*

The leftmost (x) coordinate which is the inclusive start of the bounding box in the horizontal
direction.

___

### `Const` CC_STAT_MAX

• **CC_STAT_MAX**: *[ConnectedComponentsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentstypes)*

*Defined in [types/opencv/imgproc_shape.ts:553](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L553)*

___

### `Const` CC_STAT_TOP

• **CC_STAT_TOP**: *[ConnectedComponentsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentstypes)*

*Defined in [types/opencv/imgproc_shape.ts:545](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L545)*

The topmost (y) coordinate which is the inclusive start of the bounding box in the vertical
direction.

___

### `Const` CC_STAT_WIDTH

• **CC_STAT_WIDTH**: *[ConnectedComponentsTypes](_types_opencv_imgproc_shape_.md#connectedcomponentstypes)*

*Defined in [types/opencv/imgproc_shape.ts:547](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L547)*

___

### `Const` CHAIN_APPROX_NONE

• **CHAIN_APPROX_NONE**: *[ContourApproximationModes](_types_opencv_imgproc_shape_.md#contourapproximationmodes)*

*Defined in [types/opencv/imgproc_shape.ts:561](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L561)*

stores absolutely all the contour points. That is, any 2 subsequent points (x1,y1) and (x2,y2) of
the contour will be either horizontal, vertical or diagonal neighbors, that is,
max(abs(x1-x2),abs(y2-y1))==1.

___

### `Const` CHAIN_APPROX_SIMPLE

• **CHAIN_APPROX_SIMPLE**: *[ContourApproximationModes](_types_opencv_imgproc_shape_.md#contourapproximationmodes)*

*Defined in [types/opencv/imgproc_shape.ts:568](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L568)*

compresses horizontal, vertical, and diagonal segments and leaves only their end points. For
example, an up-right rectangular contour is encoded with 4 points.

___

### `Const` CHAIN_APPROX_TC89_KCOS

• **CHAIN_APPROX_TC89_KCOS**: *[ContourApproximationModes](_types_opencv_imgproc_shape_.md#contourapproximationmodes)*

*Defined in [types/opencv/imgproc_shape.ts:580](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L580)*

applies one of the flavors of the Teh-Chin chain approximation algorithm TehChin89

___

### `Const` CHAIN_APPROX_TC89_L1

• **CHAIN_APPROX_TC89_L1**: *[ContourApproximationModes](_types_opencv_imgproc_shape_.md#contourapproximationmodes)*

*Defined in [types/opencv/imgproc_shape.ts:574](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L574)*

applies one of the flavors of the Teh-Chin chain approximation algorithm TehChin89

___

### `Const` CONTOURS_MATCH_I1

• **CONTOURS_MATCH_I1**: *[ShapeMatchModes](_types_opencv_imgproc_shape_.md#shapematchmodes)*

*Defined in [types/opencv/imgproc_shape.ts:618](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L618)*

___

### `Const` CONTOURS_MATCH_I2

• **CONTOURS_MATCH_I2**: *[ShapeMatchModes](_types_opencv_imgproc_shape_.md#shapematchmodes)*

*Defined in [types/opencv/imgproc_shape.ts:620](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L620)*

___

### `Const` CONTOURS_MATCH_I3

• **CONTOURS_MATCH_I3**: *[ShapeMatchModes](_types_opencv_imgproc_shape_.md#shapematchmodes)*

*Defined in [types/opencv/imgproc_shape.ts:622](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L622)*

___

### `Const` INTERSECT_FULL

• **INTERSECT_FULL**: *[RectanglesIntersectTypes](_types_opencv_imgproc_shape_.md#rectanglesintersecttypes)*

*Defined in [types/opencv/imgproc_shape.ts:586](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L586)*

___

### `Const` INTERSECT_NONE

• **INTERSECT_NONE**: *[RectanglesIntersectTypes](_types_opencv_imgproc_shape_.md#rectanglesintersecttypes)*

*Defined in [types/opencv/imgproc_shape.ts:582](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L582)*

___

### `Const` INTERSECT_PARTIAL

• **INTERSECT_PARTIAL**: *[RectanglesIntersectTypes](_types_opencv_imgproc_shape_.md#rectanglesintersecttypes)*

*Defined in [types/opencv/imgproc_shape.ts:584](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L584)*

___

### `Const` RETR_CCOMP

• **RETR_CCOMP**: *[RetrievalModes](_types_opencv_imgproc_shape_.md#retrievalmodes)*

*Defined in [types/opencv/imgproc_shape.ts:608](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L608)*

retrieves all of the contours and organizes them into a two-level hierarchy. At the top level, there
are external boundaries of the components. At the second level, there are boundaries of the holes.
If there is another contour inside a hole of a connected component, it is still put at the top
level.

___

### `Const` RETR_EXTERNAL

• **RETR_EXTERNAL**: *[RetrievalModes](_types_opencv_imgproc_shape_.md#retrievalmodes)*

*Defined in [types/opencv/imgproc_shape.ts:593](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L593)*

retrieves only the extreme outer contours. It sets `hierarchy[i][2]=hierarchy[i][3]=-1` for all the
contours.

___

### `Const` RETR_FLOODFILL

• **RETR_FLOODFILL**: *[RetrievalModes](_types_opencv_imgproc_shape_.md#retrievalmodes)*

*Defined in [types/opencv/imgproc_shape.ts:616](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L616)*

___

### `Const` RETR_LIST

• **RETR_LIST**: *[RetrievalModes](_types_opencv_imgproc_shape_.md#retrievalmodes)*

*Defined in [types/opencv/imgproc_shape.ts:599](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L599)*

retrieves all of the contours without establishing any hierarchical relationships.

___

### `Const` RETR_TREE

• **RETR_TREE**: *[RetrievalModes](_types_opencv_imgproc_shape_.md#retrievalmodes)*

*Defined in [types/opencv/imgproc_shape.ts:614](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L614)*

retrieves all of the contours and reconstructs a full hierarchy of nested contours.

## Functions

###  HuMoments

▸ **HuMoments**(`moments`: any, `hu`: [double](_types_opencv__hacks_.md#double)): *void*

*Defined in [types/opencv/imgproc_shape.ts:403](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L403)*

The function calculates seven Hu invariants (introduced in Hu62; see also ) defined as:

`\\[\\begin{array}{l} hu[0]= \\eta _{20}+ \\eta _{02} \\\\ hu[1]=( \\eta _{20}- \\eta _{02})^{2}+4
\\eta _{11}^{2} \\\\ hu[2]=( \\eta _{30}-3 \\eta _{12})^{2}+ (3 \\eta _{21}- \\eta _{03})^{2} \\\\
hu[3]=( \\eta _{30}+ \\eta _{12})^{2}+ ( \\eta _{21}+ \\eta _{03})^{2} \\\\ hu[4]=( \\eta _{30}-3
\\eta _{12})( \\eta _{30}+ \\eta _{12})[( \\eta _{30}+ \\eta _{12})^{2}-3( \\eta _{21}+ \\eta
_{03})^{2}]+(3 \\eta _{21}- \\eta _{03})( \\eta _{21}+ \\eta _{03})[3( \\eta _{30}+ \\eta
_{12})^{2}-( \\eta _{21}+ \\eta _{03})^{2}] \\\\ hu[5]=( \\eta _{20}- \\eta _{02})[( \\eta _{30}+
\\eta _{12})^{2}- ( \\eta _{21}+ \\eta _{03})^{2}]+4 \\eta _{11}( \\eta _{30}+ \\eta _{12})( \\eta
_{21}+ \\eta _{03}) \\\\ hu[6]=(3 \\eta _{21}- \\eta _{03})( \\eta _{21}+ \\eta _{03})[3( \\eta
_{30}+ \\eta _{12})^{2}-( \\eta _{21}+ \\eta _{03})^{2}]-( \\eta _{30}-3 \\eta _{12})( \\eta _{21}+
\\eta _{03})[3( \\eta _{30}+ \\eta _{12})^{2}-( \\eta _{21}+ \\eta _{03})^{2}] \\\\ \\end{array}\\]`

where `$\\eta_{ji}$` stands for `$\\texttt{Moments::nu}_{ji}$` .

These values are proved to be invariants to the image scale, rotation, and reflection except the
seventh one, whose sign is changed by reflection. This invariance is proved with the assumption of
infinite image resolution. In case of raster images, the computed Hu invariants for the original and
transformed images are a bit different.

[matchShapes]

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`moments` | any | Input moments computed with moments .  |
`hu` | [double](_types_opencv__hacks_.md#double) | Output Hu invariants.  |

**Returns:** *void*

▸ **HuMoments**(`m`: any, `hu`: OutputArray): *void*

*Defined in [types/opencv/imgproc_shape.ts:409](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L409)*

This is an overloaded member function, provided for convenience. It differs from the above function
only in what argument(s) it accepts.

**Parameters:**

Name | Type |
------ | ------ |
`m` | any |
`hu` | OutputArray |

**Returns:** *void*

___

###  approxPolyDP

▸ **approxPolyDP**(`curve`: InputArray, `approxCurve`: OutputArray, `epsilon`: [double](_types_opencv__hacks_.md#double), `closed`: [bool](_types_opencv__hacks_.md#bool)): *void*

*Defined in [types/opencv/imgproc_shape.ts:22](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L22)*

The function [cv::approxPolyDP] approximates a curve or a polygon with another curve/polygon with
less vertices so that the distance between them is less or equal to the specified precision. It uses
the Douglas-Peucker algorithm

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`curve` | InputArray | Input vector of a 2D point stored in std::vector or Mat  |
`approxCurve` | OutputArray | Result of the approximation. The type should match the type of the input curve.  |
`epsilon` | [double](_types_opencv__hacks_.md#double) | Parameter specifying the approximation accuracy. This is the maximum distance between the original curve and its approximation.  |
`closed` | [bool](_types_opencv__hacks_.md#bool) | If true, the approximated curve is closed (its first and last vertices are connected). Otherwise, it is not closed.  |

**Returns:** *void*

___

###  arcLength

▸ **arcLength**(`curve`: InputArray, `closed`: [bool](_types_opencv__hacks_.md#bool)): *[double](_types_opencv__hacks_.md#double)*

*Defined in [types/opencv/imgproc_shape.ts:31](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L31)*

The function computes a curve length or a closed contour perimeter.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`curve` | InputArray | Input vector of 2D points, stored in std::vector or Mat.  |
`closed` | [bool](_types_opencv__hacks_.md#bool) | Flag indicating whether the curve is closed or not.  |

**Returns:** *[double](_types_opencv__hacks_.md#double)*

___

###  boundingRect

▸ **boundingRect**(`array`: InputArray): *[Rect](../classes/_types_opencv__hacks_.rect.md)*

*Defined in [types/opencv/imgproc_shape.ts:39](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L39)*

The function calculates and returns the minimal up-right bounding rectangle for the specified point
set or non-zero pixels of gray-scale image.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`array` | InputArray | Input gray-scale image or 2D point set, stored in std::vector or Mat.  |

**Returns:** *[Rect](../classes/_types_opencv__hacks_.rect.md)*

___

###  boxPoints

▸ **boxPoints**(`box`: [RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md), `points`: OutputArray): *void*

*Defined in [types/opencv/imgproc_shape.ts:51](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L51)*

The function finds the four vertices of a rotated rectangle. This function is useful to draw the
rectangle. In C++, instead of using this function, you can directly use [RotatedRect::points]
method. Please visit the [tutorial on Creating Bounding rotated boxes and ellipses for contours] for
more information.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`box` | [RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md) | The input rotated rectangle. It may be the output of  |
`points` | OutputArray | The output array of four vertices of rectangles.  |

**Returns:** *void*

___

###  connectedComponents

▸ **connectedComponents**(`image`: InputArray, `labels`: OutputArray, `connectivity`: [int](_types_opencv__hacks_.md#int), `ltype`: [int](_types_opencv__hacks_.md#int), `ccltype`: [int](_types_opencv__hacks_.md#int)): *[int](_types_opencv__hacks_.md#int)*

*Defined in [types/opencv/imgproc_shape.ts:74](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L74)*

image with 4 or 8 way connectivity - returns N, the total number of labels [0, N-1] where 0
represents the background label. ltype specifies the output label image type, an important
consideration based on the total number of labels or alternatively the total number of pixels in the
source image. ccltype specifies the connected components labeling algorithm to use, currently Grana
(BBDT) and Wu's (SAUF) algorithms are supported, see the [ConnectedComponentsAlgorithmsTypes] for
details. Note that SAUF algorithm forces a row major ordering of labels while BBDT does not. This
function uses parallel version of both Grana and Wu's algorithms if at least one allowed parallel
framework is enabled and if the rows of the image are at least twice the number returned by
[getNumberOfCPUs].

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`image` | InputArray | the 8-bit single-channel image to be labeled  |
`labels` | OutputArray | destination labeled image  |
`connectivity` | [int](_types_opencv__hacks_.md#int) | 8 or 4 for 8-way or 4-way connectivity respectively  |
`ltype` | [int](_types_opencv__hacks_.md#int) | output image label type. Currently CV_32S and CV_16U are supported.  |
`ccltype` | [int](_types_opencv__hacks_.md#int) | connected components algorithm type (see the ConnectedComponentsAlgorithmsTypes).  |

**Returns:** *[int](_types_opencv__hacks_.md#int)*

▸ **connectedComponents**(`image`: InputArray, `labels`: OutputArray, `connectivity?`: [int](_types_opencv__hacks_.md#int), `ltype?`: [int](_types_opencv__hacks_.md#int)): *[int](_types_opencv__hacks_.md#int)*

*Defined in [types/opencv/imgproc_shape.ts:88](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L88)*

This is an overloaded member function, provided for convenience. It differs from the above function
only in what argument(s) it accepts.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`image` | InputArray | the 8-bit single-channel image to be labeled  |
`labels` | OutputArray | destination labeled image  |
`connectivity?` | [int](_types_opencv__hacks_.md#int) | 8 or 4 for 8-way or 4-way connectivity respectively  |
`ltype?` | [int](_types_opencv__hacks_.md#int) | output image label type. Currently CV_32S and CV_16U are supported.  |

**Returns:** *[int](_types_opencv__hacks_.md#int)*

___

###  connectedComponentsWithStats

▸ **connectedComponentsWithStats**(`image`: InputArray, `labels`: OutputArray, `stats`: OutputArray, `centroids`: OutputArray, `connectivity`: [int](_types_opencv__hacks_.md#int), `ltype`: [int](_types_opencv__hacks_.md#int), `ccltype`: [int](_types_opencv__hacks_.md#int)): *[int](_types_opencv__hacks_.md#int)*

*Defined in [types/opencv/imgproc_shape.ts:118](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L118)*

image with 4 or 8 way connectivity - returns N, the total number of labels [0, N-1] where 0
represents the background label. ltype specifies the output label image type, an important
consideration based on the total number of labels or alternatively the total number of pixels in the
source image. ccltype specifies the connected components labeling algorithm to use, currently
Grana's (BBDT) and Wu's (SAUF) algorithms are supported, see the
[ConnectedComponentsAlgorithmsTypes] for details. Note that SAUF algorithm forces a row major
ordering of labels while BBDT does not. This function uses parallel version of both Grana and Wu's
algorithms (statistics included) if at least one allowed parallel framework is enabled and if the
rows of the image are at least twice the number returned by [getNumberOfCPUs].

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`image` | InputArray | the 8-bit single-channel image to be labeled  |
`labels` | OutputArray | destination labeled image  |
`stats` | OutputArray | statistics output for each label, including the background label, see below for available statistics. Statistics are accessed via stats(label, COLUMN) where COLUMN is one of ConnectedComponentsTypes. The data type is CV_32S.  |
`centroids` | OutputArray | centroid output for each label, including the background label. Centroids are accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.  |
`connectivity` | [int](_types_opencv__hacks_.md#int) | 8 or 4 for 8-way or 4-way connectivity respectively  |
`ltype` | [int](_types_opencv__hacks_.md#int) | output image label type. Currently CV_32S and CV_16U are supported.  |
`ccltype` | [int](_types_opencv__hacks_.md#int) | connected components algorithm type (see ConnectedComponentsAlgorithmsTypes).  |

**Returns:** *[int](_types_opencv__hacks_.md#int)*

▸ **connectedComponentsWithStats**(`image`: InputArray, `labels`: OutputArray, `stats`: OutputArray, `centroids`: OutputArray, `connectivity?`: [int](_types_opencv__hacks_.md#int), `ltype?`: [int](_types_opencv__hacks_.md#int)): *[int](_types_opencv__hacks_.md#int)*

*Defined in [types/opencv/imgproc_shape.ts:139](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L139)*

This is an overloaded member function, provided for convenience. It differs from the above function
only in what argument(s) it accepts.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`image` | InputArray | the 8-bit single-channel image to be labeled  |
`labels` | OutputArray | destination labeled image  |
`stats` | OutputArray | statistics output for each label, including the background label, see below for available statistics. Statistics are accessed via stats(label, COLUMN) where COLUMN is one of ConnectedComponentsTypes. The data type is CV_32S.  |
`centroids` | OutputArray | centroid output for each label, including the background label. Centroids are accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.  |
`connectivity?` | [int](_types_opencv__hacks_.md#int) | 8 or 4 for 8-way or 4-way connectivity respectively  |
`ltype?` | [int](_types_opencv__hacks_.md#int) | output image label type. Currently CV_32S and CV_16U are supported.  |

**Returns:** *[int](_types_opencv__hacks_.md#int)*

___

###  contourArea

▸ **contourArea**(`contour`: InputArray, `oriented?`: [bool](_types_opencv__hacks_.md#bool)): *[double](_types_opencv__hacks_.md#double)*

*Defined in [types/opencv/imgproc_shape.ts:173](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L173)*

The function computes a contour area. Similarly to moments , the area is computed using the Green
formula. Thus, the returned area and the number of non-zero pixels, if you draw the contour using
[drawContours] or [fillPoly] , can be different. Also, the function will most certainly give a wrong
results for contours with self-intersections.

Example:

```cpp
vector<Point> contour;
contour.push_back(Point2f(0, 0));
contour.push_back(Point2f(10, 0));
contour.push_back(Point2f(10, 10));
contour.push_back(Point2f(5, 4));

double area0 = contourArea(contour);
vector<Point> approx;
approxPolyDP(contour, approx, 5, true);
double area1 = contourArea(approx);

cout << "area0 =" << area0 << endl <<
        "area1 =" << area1 << endl <<
        "approx poly vertices" << approx.size() << endl;
```

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`contour` | InputArray | Input vector of 2D points (contour vertices), stored in std::vector or Mat.  |
`oriented?` | [bool](_types_opencv__hacks_.md#bool) | Oriented area flag. If it is true, the function returns a signed area value, depending on the contour orientation (clockwise or counter-clockwise). Using this feature you can determine orientation of a contour by taking the sign of an area. By default, the parameter is false, which means that the absolute value is returned.  |

**Returns:** *[double](_types_opencv__hacks_.md#double)*

___

###  convexHull

▸ **convexHull**(`points`: InputArray, `hull`: OutputArray, `clockwise?`: [bool](_types_opencv__hacks_.md#bool), `returnPoints?`: [bool](_types_opencv__hacks_.md#bool)): *void*

*Defined in [types/opencv/imgproc_shape.ts:200](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L200)*

The function [cv::convexHull] finds the convex hull of a 2D point set using the Sklansky's algorithm
Sklansky82 that has *O(N logN)* complexity in the current implementation.

`points` and `hull` should be different arrays, inplace processing isn't supported.
Check [the corresponding tutorial] for more details.

useful links:

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`points` | InputArray | Input 2D point set, stored in std::vector or Mat.  |
`hull` | OutputArray | Output convex hull. It is either an integer vector of indices or vector of points. In the first case, the hull elements are 0-based indices of the convex hull points in the original array (since the set of convex hull points is a subset of the original point set). In the second case, hull elements are the convex hull points themselves.  |
`clockwise?` | [bool](_types_opencv__hacks_.md#bool) | Orientation flag. If it is true, the output convex hull is oriented clockwise. Otherwise, it is oriented counter-clockwise. The assumed coordinate system has its X axis pointing to the right, and its Y axis pointing upwards.  |
`returnPoints?` | [bool](_types_opencv__hacks_.md#bool) | Operation flag. In case of a matrix, when the flag is true, the function returns convex hull points. Otherwise, it returns indices of the convex hull points. When the output array is std::vector, the flag is ignored, and the output depends on the type of the vector: std::vector<int> implies returnPoints=false, std::vector<Point> implies returnPoints=true.  |

**Returns:** *void*

___

###  convexityDefects

▸ **convexityDefects**(`contour`: InputArray, `convexhull`: InputArray, `convexityDefects`: OutputArray): *void*

*Defined in [types/opencv/imgproc_shape.ts:217](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L217)*

The figure below displays convexity defects of a hand contour:

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`contour` | InputArray | Input contour.  |
`convexhull` | InputArray | Convex hull obtained using convexHull that should contain indices of the contour points that make the hull.  |
`convexityDefects` | OutputArray | The output vector of convexity defects. In C++ and the new Python/Java interface each convexity defect is represented as 4-element integer vector (a.k.a. Vec4i): (start_index, end_index, farthest_pt_index, fixpt_depth), where indices are 0-based indices in the original contour of the convexity defect beginning, end and the farthest point, and fixpt_depth is fixed-point approximation (with 8 fractional bits) of the distance between the farthest contour point and the hull. That is, to get the floating-point value of the depth will be fixpt_depth/256.0.  |

**Returns:** *void*

___

###  createGeneralizedHoughBallard

▸ **createGeneralizedHoughBallard**(): *any*

*Defined in [types/opencv/imgproc_shape.ts:219](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L219)*

**Returns:** *any*

___

###  createGeneralizedHoughGuil

▸ **createGeneralizedHoughGuil**(): *any*

*Defined in [types/opencv/imgproc_shape.ts:221](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L221)*

**Returns:** *any*

___

###  findContours

▸ **findContours**(`image`: InputArray, `contours`: OutputArrayOfArrays, `hierarchy`: OutputArray, `mode`: [int](_types_opencv__hacks_.md#int), `method`: [int](_types_opencv__hacks_.md#int), `offset?`: [Point](../classes/_types_opencv__hacks_.point.md)): *void*

*Defined in [types/opencv/imgproc_shape.ts:255](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L255)*

The function retrieves contours from the binary image using the algorithm Suzuki85 . The contours
are a useful tool for shape analysis and object detection and recognition. See squares.cpp in the
OpenCV sample directory.

Since opencv 3.2 source image is not modified by this function.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`image` | InputArray | Source, an 8-bit single-channel image. Non-zero pixels are treated as 1's. Zero pixels remain 0's, so the image is treated as binary . You can use compare, inRange, threshold , adaptiveThreshold, Canny, and others to create a binary image out of a grayscale or color one. If mode equals to RETR_CCOMP or RETR_FLOODFILL, the input can also be a 32-bit integer image of labels (CV_32SC1).  |
`contours` | OutputArrayOfArrays | Detected contours. Each contour is stored as a vector of points (e.g. std::vector<std::vector<cv::Point> >).  |
`hierarchy` | OutputArray | Optional output vector (e.g. std::vector<cv::Vec4i>), containing information about the image topology. It has as many elements as the number of contours. For each i-th contour contours[i], the elements hierarchy[i][0] , hierarchy[i][1] , hierarchy[i][2] , and hierarchy[i][3] are set to 0-based indices in contours of the next and previous contours at the same hierarchical level, the first child contour and the parent contour, respectively. If for the contour i there are no next, previous, parent, or nested contours, the corresponding elements of hierarchy[i] will be negative.  |
`mode` | [int](_types_opencv__hacks_.md#int) | Contour retrieval mode, see RetrievalModes  |
`method` | [int](_types_opencv__hacks_.md#int) | Contour approximation method, see ContourApproximationModes  |
`offset?` | [Point](../classes/_types_opencv__hacks_.point.md) | Optional offset by which every contour point is shifted. This is useful if the contours are extracted from the image ROI and then they should be analyzed in the whole image context.  |

**Returns:** *void*

▸ **findContours**(`image`: InputArray, `contours`: OutputArrayOfArrays, `mode`: [int](_types_opencv__hacks_.md#int), `method`: [int](_types_opencv__hacks_.md#int), `offset?`: [Point](../classes/_types_opencv__hacks_.point.md)): *void*

*Defined in [types/opencv/imgproc_shape.ts:261](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L261)*

This is an overloaded member function, provided for convenience. It differs from the above function
only in what argument(s) it accepts.

**Parameters:**

Name | Type |
------ | ------ |
`image` | InputArray |
`contours` | OutputArrayOfArrays |
`mode` | [int](_types_opencv__hacks_.md#int) |
`method` | [int](_types_opencv__hacks_.md#int) |
`offset?` | [Point](../classes/_types_opencv__hacks_.point.md) |

**Returns:** *void*

___

###  fitEllipse

▸ **fitEllipse**(`points`: InputArray): *[RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md)*

*Defined in [types/opencv/imgproc_shape.ts:272](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L272)*

The function calculates the ellipse that fits (in a least-squares sense) a set of 2D points best of
all. It returns the rotated rectangle in which the ellipse is inscribed. The first algorithm
described by Fitzgibbon95 is used. Developer should keep in mind that it is possible that the
returned ellipse/rotatedRect data contains negative indices, due to the data points being close to
the border of the containing [Mat] element.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`points` | InputArray | Input 2D point set, stored in std::vector<> or Mat  |

**Returns:** *[RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md)*

___

###  fitEllipseAMS

▸ **fitEllipseAMS**(`points`: InputArray): *[RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md)*

*Defined in [types/opencv/imgproc_shape.ts:300](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L300)*

The function calculates the ellipse that fits a set of 2D points. It returns the rotated rectangle
in which the ellipse is inscribed. The Approximate Mean Square (AMS) proposed by Taubin1991 is used.

For an ellipse, this basis set is `$ \\chi= \\left(x^2, x y, y^2, x, y, 1\\right) $`, which is a set
of six free coefficients `$
A^T=\\left\\{A_{\\text{xx}},A_{\\text{xy}},A_{\\text{yy}},A_x,A_y,A_0\\right\\} $`. However, to
specify an ellipse, all that is needed is five numbers; the major and minor axes lengths `$ (a,b)
$`, the position `$ (x_0,y_0) $`, and the orientation `$ \\theta $`. This is because the basis set
includes lines, quadratics, parabolic and hyperbolic functions as well as elliptical functions as
possible fits. If the fit is found to be a parabolic or hyperbolic function then the standard
[fitEllipse] method is used. The AMS method restricts the fit to parabolic, hyperbolic and
elliptical curves by imposing the condition that `$ A^T ( D_x^T D_x + D_y^T D_y) A = 1 $` where the
matrices `$ Dx $` and `$ Dy $` are the partial derivatives of the design matrix `$ D $` with respect
to x and y. The matrices are formed row by row applying the following to each of the points in the
set: `\\begin{align*} D(i,:)&=\\left\\{x_i^2, x_i y_i, y_i^2, x_i, y_i, 1\\right\\} &
D_x(i,:)&=\\left\\{2 x_i,y_i,0,1,0,0\\right\\} & D_y(i,:)&=\\left\\{0,x_i,2 y_i,0,1,0\\right\\}
\\end{align*}` The AMS method minimizes the cost function `\\begin{equation*} \\epsilon ^2=\\frac{
A^T D^T D A }{ A^T (D_x^T D_x + D_y^T D_y) A^T } \\end{equation*}`

The minimum cost is found by solving the generalized eigenvalue problem.

`\\begin{equation*} D^T D A = \\lambda \\left( D_x^T D_x + D_y^T D_y\\right) A \\end{equation*}`

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`points` | InputArray | Input 2D point set, stored in std::vector<> or Mat  |

**Returns:** *[RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md)*

___

###  fitEllipseDirect

▸ **fitEllipseDirect**(`points`: InputArray): *[RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md)*

*Defined in [types/opencv/imgproc_shape.ts:334](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L334)*

The function calculates the ellipse that fits a set of 2D points. It returns the rotated rectangle
in which the ellipse is inscribed. The Direct least square (Direct) method by Fitzgibbon1999 is
used.

For an ellipse, this basis set is `$ \\chi= \\left(x^2, x y, y^2, x, y, 1\\right) $`, which is a set
of six free coefficients `$
A^T=\\left\\{A_{\\text{xx}},A_{\\text{xy}},A_{\\text{yy}},A_x,A_y,A_0\\right\\} $`. However, to
specify an ellipse, all that is needed is five numbers; the major and minor axes lengths `$ (a,b)
$`, the position `$ (x_0,y_0) $`, and the orientation `$ \\theta $`. This is because the basis set
includes lines, quadratics, parabolic and hyperbolic functions as well as elliptical functions as
possible fits. The Direct method confines the fit to ellipses by ensuring that `$ 4 A_{xx} A_{yy}-
A_{xy}^2 > 0 $`. The condition imposed is that `$ 4 A_{xx} A_{yy}- A_{xy}^2=1 $` which satisfies the
inequality and as the coefficients can be arbitrarily scaled is not overly restrictive.

`\\begin{equation*} \\epsilon ^2= A^T D^T D A \\quad \\text{with} \\quad A^T C A =1 \\quad
\\text{and} \\quad C=\\left(\\begin{matrix} 0 & 0 & 2 & 0 & 0 & 0 \\\\ 0 & -1 & 0 & 0 & 0 & 0 \\\\ 2
& 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0
\\end{matrix} \\right) \\end{equation*}`

The minimum cost is found by solving the generalized eigenvalue problem.

`\\begin{equation*} D^T D A = \\lambda \\left( C\\right) A \\end{equation*}`

The system produces only one positive eigenvalue `$ \\lambda$` which is chosen as the solution with
its eigenvector `$\\mathbf{u}$`. These are used to find the coefficients

`\\begin{equation*} A = \\sqrt{\\frac{1}{\\mathbf{u}^T C \\mathbf{u}}} \\mathbf{u} \\end{equation*}`
The scaling factor guarantees that `$A^T C A =1$`.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`points` | InputArray | Input 2D point set, stored in std::vector<> or Mat  |

**Returns:** *[RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md)*

___

###  fitLine

▸ **fitLine**(`points`: InputArray, `line`: OutputArray, `distType`: [int](_types_opencv__hacks_.md#int), `param`: [double](_types_opencv__hacks_.md#double), `reps`: [double](_types_opencv__hacks_.md#double), `aeps`: [double](_types_opencv__hacks_.md#double)): *void*

*Defined in [types/opencv/imgproc_shape.ts:374](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L374)*

The function fitLine fits a line to a 2D or 3D point set by minimizing `$\\sum_i \\rho(r_i)$` where
`$r_i$` is a distance between the `$i^{th}$` point, the line and `$\\rho(r)$` is a distance
function, one of the following:

DIST_L2 `\\[\\rho (r) = r^2/2 \\quad \\text{(the simplest and the fastest least-squares method)}\\]`
DIST_L1 `\\[\\rho (r) = r\\]`
DIST_L12 `\\[\\rho (r) = 2 \\cdot ( \\sqrt{1 + \\frac{r^2}{2}} - 1)\\]`
DIST_FAIR `\\[\\rho \\left (r \\right ) = C^2 \\cdot \\left ( \\frac{r}{C} - \\log{\\left(1 +
\\frac{r}{C}\\right)} \\right ) \\quad \\text{where} \\quad C=1.3998\\]`
DIST_WELSCH `\\[\\rho \\left (r \\right ) = \\frac{C^2}{2} \\cdot \\left ( 1 -
\\exp{\\left(-\\left(\\frac{r}{C}\\right)^2\\right)} \\right ) \\quad \\text{where} \\quad
C=2.9846\\]`
DIST_HUBER `\\[\\rho (r) = \\fork{r^2/2}{if \\(r < C\\)}{C \\cdot (r-C/2)}{otherwise} \\quad
\\text{where} \\quad C=1.345\\]`

The algorithm is based on the M-estimator (  ) technique that iteratively fits the line using the
weighted least-squares algorithm. After each iteration the weights `$w_i$` are adjusted to be
inversely proportional to `$\\rho(r_i)$` .

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`points` | InputArray | Input vector of 2D or 3D points, stored in std::vector<> or Mat.  |
`line` | OutputArray | Output line parameters. In case of 2D fitting, it should be a vector of 4 elements (like Vec4f) - (vx, vy, x0, y0), where (vx, vy) is a normalized vector collinear to the line and (x0, y0) is a point on the line. In case of 3D fitting, it should be a vector of 6 elements (like Vec6f) - (vx, vy, vz, x0, y0, z0), where (vx, vy, vz) is a normalized vector collinear to the line and (x0, y0, z0) is a point on the line.  |
`distType` | [int](_types_opencv__hacks_.md#int) | Distance used by the M-estimator, see DistanceTypes  |
`param` | [double](_types_opencv__hacks_.md#double) | Numerical parameter ( C ) for some types of distances. If it is 0, an optimal value is chosen.  |
`reps` | [double](_types_opencv__hacks_.md#double) | Sufficient accuracy for the radius (distance between the coordinate origin and the line).  |
`aeps` | [double](_types_opencv__hacks_.md#double) | Sufficient accuracy for the angle. 0.01 would be a good default value for reps and aeps.  |

**Returns:** *void*

___

###  intersectConvexConvex

▸ **intersectConvexConvex**(`_p1`: InputArray, `_p2`: InputArray, `_p12`: OutputArray, `handleNested?`: [bool](_types_opencv__hacks_.md#bool)): *[float](_types_opencv__hacks_.md#float)*

*Defined in [types/opencv/imgproc_shape.ts:411](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L411)*

**Parameters:**

Name | Type |
------ | ------ |
`_p1` | InputArray |
`_p2` | InputArray |
`_p12` | OutputArray |
`handleNested?` | [bool](_types_opencv__hacks_.md#bool) |

**Returns:** *[float](_types_opencv__hacks_.md#float)*

___

###  isContourConvex

▸ **isContourConvex**(`contour`: InputArray): *[bool](_types_opencv__hacks_.md#bool)*

*Defined in [types/opencv/imgproc_shape.ts:419](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L419)*

The function tests whether the input contour is convex or not. The contour must be simple, that is,
without self-intersections. Otherwise, the function output is undefined.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`contour` | InputArray | Input vector of 2D points, stored in std::vector<> or Mat  |

**Returns:** *[bool](_types_opencv__hacks_.md#bool)*

___

###  matchShapes

▸ **matchShapes**(`contour1`: InputArray, `contour2`: InputArray, `method`: [int](_types_opencv__hacks_.md#int), `parameter`: [double](_types_opencv__hacks_.md#double)): *[double](_types_opencv__hacks_.md#double)*

*Defined in [types/opencv/imgproc_shape.ts:433](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L433)*

The function compares two shapes. All three implemented methods use the Hu invariants (see
[HuMoments])

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`contour1` | InputArray | First contour or grayscale image.  |
`contour2` | InputArray | Second contour or grayscale image.  |
`method` | [int](_types_opencv__hacks_.md#int) | Comparison method, see ShapeMatchModes  |
`parameter` | [double](_types_opencv__hacks_.md#double) | Method-specific parameter (not supported now).  |

**Returns:** *[double](_types_opencv__hacks_.md#double)*

___

###  minAreaRect

▸ **minAreaRect**(`points`: InputArray): *[RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md)*

*Defined in [types/opencv/imgproc_shape.ts:442](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L442)*

The function calculates and returns the minimum-area bounding rectangle (possibly rotated) for a
specified point set. Developer should keep in mind that the returned [RotatedRect] can contain
negative indices when data is close to the containing [Mat] element boundary.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`points` | InputArray | Input vector of 2D points, stored in std::vector<> or Mat  |

**Returns:** *[RotatedRect](../classes/_types_opencv_rotatedrect_.rotatedrect.md)*

___

###  minEnclosingCircle

▸ **minEnclosingCircle**(`points`: InputArray, `center`: any, `radius`: any): *void*

*Defined in [types/opencv/imgproc_shape.ts:453](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L453)*

The function finds the minimal enclosing circle of a 2D point set using an iterative algorithm.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`points` | InputArray | Input vector of 2D points, stored in std::vector<> or Mat  |
`center` | any | Output center of the circle.  |
`radius` | any | Output radius of the circle.  |

**Returns:** *void*

___

###  minEnclosingTriangle

▸ **minEnclosingTriangle**(`points`: InputArray, `triangle`: OutputArray): *[double](_types_opencv__hacks_.md#double)*

*Defined in [types/opencv/imgproc_shape.ts:472](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L472)*

The function finds a triangle of minimum area enclosing the given set of 2D points and returns its
area. The output for a given 2D point set is shown in the image below. 2D points are depicted in
red* and the enclosing triangle in *yellow*.

 The implementation of the algorithm is based on O'Rourke's ORourke86 and Klee and Laskowski's
KleeLaskowski85 papers. O'Rourke provides a `$\\theta(n)$` algorithm for finding the minimal
enclosing triangle of a 2D convex polygon with n vertices. Since the [minEnclosingTriangle] function
takes a 2D point set as input an additional preprocessing step of computing the convex hull of the
2D point set is required. The complexity of the [convexHull] function is `$O(n log(n))$` which is
higher than `$\\theta(n)$`. Thus the overall complexity of the function is `$O(n log(n))$`.

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`points` | InputArray | Input vector of 2D points with depth CV_32S or CV_32F, stored in std::vector<> or Mat  |
`triangle` | OutputArray | Output vector of three 2D points defining the vertices of the triangle. The depth of the OutputArray must be CV_32F.  |

**Returns:** *[double](_types_opencv__hacks_.md#double)*

___

###  moments

▸ **moments**(`array`: InputArray, `binaryImage?`: [bool](_types_opencv__hacks_.md#bool)): *[Moments](_types_opencv__hacks_.md#moments)*

*Defined in [types/opencv/imgproc_shape.ts:491](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L491)*

The function computes moments, up to the 3rd order, of a vector shape or a rasterized shape. The
results are returned in the structure [cv::Moments].

moments.

Only applicable to contour moments calculations from Python bindings: Note that the numpy type for
the input array should be either np.int32 or np.float32.

[contourArea], [arcLength]

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`array` | InputArray | Raster image (single-channel, 8-bit or floating-point 2D array) or an array ( $1 \times N$ or $N \times 1$ ) of 2D points (Point or Point2f ).  |
`binaryImage?` | [bool](_types_opencv__hacks_.md#bool) | If it is true, all non-zero image pixels are treated as 1's. The parameter is used for images only.  |

**Returns:** *[Moments](_types_opencv__hacks_.md#moments)*

___

###  pointPolygonTest

▸ **pointPolygonTest**(`contour`: InputArray, `pt`: Point2f, `measureDist`: [bool](_types_opencv__hacks_.md#bool)): *[double](_types_opencv__hacks_.md#double)*

*Defined in [types/opencv/imgproc_shape.ts:508](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L508)*

The function determines whether the point is inside a contour, outside, or lies on an edge (or
coincides with a vertex). It returns positive (inside), negative (outside), or zero (on an edge)
value, correspondingly. When measureDist=false , the return value is +1, -1, and 0, respectively.
Otherwise, the return value is a signed distance between the point and the nearest contour edge.

See below a sample output of the function where each image pixel is tested against the contour:

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`contour` | InputArray | Input contour.  |
`pt` | Point2f | Point tested against the contour.  |
`measureDist` | [bool](_types_opencv__hacks_.md#bool) | If true, the function estimates the signed distance from the point to the nearest contour edge. Otherwise, the function only checks if the point is inside a contour or not.  |

**Returns:** *[double](_types_opencv__hacks_.md#double)*

___

###  rotatedRectangleIntersection

▸ **rotatedRectangleIntersection**(`rect1`: any, `rect2`: any, `intersectingRegion`: OutputArray): *[int](_types_opencv__hacks_.md#int)*

*Defined in [types/opencv/imgproc_shape.ts:525](https://github.com/cancerberoSgx/mirada/blob/c8721d6/mirada/src/types/opencv/imgproc_shape.ts#L525)*

If there is then the vertices of the intersecting region are returned as well.

Below are some examples of intersection configurations. The hatched pattern indicates the
intersecting region and the red vertices are returned by the function.

One of [RectanglesIntersectTypes]

**Parameters:**

Name | Type | Description |
------ | ------ | ------ |
`rect1` | any | First rectangle  |
`rect2` | any | Second rectangle  |
`intersectingRegion` | OutputArray | The output array of the vertices of the intersecting region. It returns at most 8 vertices. Stored as std::vector<cv::Point2f> or cv::Mat as Mx1 of type CV_32FC2.  |

**Returns:** *[int](_types_opencv__hacks_.md#int)*